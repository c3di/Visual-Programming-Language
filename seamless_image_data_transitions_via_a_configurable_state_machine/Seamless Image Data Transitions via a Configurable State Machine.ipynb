{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Seamless Image Data Transitions via a Configurable State Machine\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "**Core Objectives**:\n",
        "\n",
        "1. **Unified Representation**: Offer a consistent, structured approach to representing images, irrespective of the computational or storage context.\n",
        "\n",
        "2. **Facilitate Seamless Transitioning**: With this structure, transitioning from one operation to another, be it processing, analysis, or storage, becomes a straightforward task, eliminating tedious manual conversions.\n",
        "\n",
        "3. **Automation via State Machine**: By modeling each data type like \"numpy.ndarray\" or \"torch.tensor\" as distinct states, and with transition rules acting as connectors, we achieve a state machine that orchestrates conversions automatically.\n",
        "\n",
        "\n",
        "We develop a high-level abstraction (Image) to make image data manipulation more efficient and less error-prone. By coupling this with a state machine model, it can automate the process of data type conversion based on transition rules, making the entire process smoother."
      ],
      "metadata": {
        "id": "skfZFBSjNk6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Image` Data Structure\n",
        "``` typescript\n",
        "interface ImageMetadata {\n",
        "  colorSpace: 'rgb' | 'gbr' | 'grayscale';\n",
        "  channelOrder: 'none' | 'first' | 'last';\n",
        "  isBatched: boolean;\n",
        "  intensityRange: '0-255' | '0-1';\n",
        "  device: 'cpu' | 'gpu';\n",
        "}\n",
        "\n",
        "interface ISourceImage {\n",
        "  dataType: string;\n",
        "  value: any;\n",
        "  metadata: ImageMetadata;\n",
        "}\n",
        "\n",
        "interface IDestinationImage {\n",
        "  dataType: string;\n",
        "  value: any;\n",
        "  metadata: ImageMetadata[];\n",
        "}\n",
        "\n",
        "export type Image = ISourceImage | IDestinationImage;\n",
        "```\n",
        "The `Image` structure encapsulates digital image data and associated metadata, providing a comprehensive representation optimized for streamlined image processing, analysis, and storage.\n",
        "\n",
        "**Attributes**:\n",
        "\n",
        "- **dataType** (`str`): A string denoting the format of the image data. Examples include \"numpy.ndarray\" for scientific computing, and \"torch.tensor\" for machine learning tasks.\n",
        "\n",
        "- **value** (`Any`): Holds the raw image data, compatible with the structure indicated by `dataType`.\n",
        "\n",
        "- **metadata** (`Union[Dict, List[Dict]]`): Captures critical descriptors about the image. Depending on the image's usage(Source  vs. Destination), this can be a singular dictionary or a list of dictionaries.\n",
        "\n",
        "  **Metadata Components**:\n",
        "\n",
        "  - **colorSpace** (`str`): Specifies the color representation schema. Options include `rgb` (Red-Green-Blue), `gbr` (Green-Blue-Red), and `grayscale`.\n",
        "\n",
        "  - **channelOrder** (`str`): Denotes the layout of color channels. Permissible values are `none` (no specific channel order), `first` (channels precede spatial dimensions), and `last` (channels follow spatial dimensions).\n",
        "\n",
        "  - **isBatched** (`bool`): A flag indicating whether the image data is part of a batch.\n",
        "\n",
        "  - **intensityRange** (`str`): Defines the pixel intensity spectrum. Common values are `0-255` (8-bit depth) and `0-1` (normalized).\n",
        "\n",
        "  - **device** (`str`): Highlights the computational platform (e.g., `cpu` or `gpu`) where the image data resides and is primed for operations.\n",
        "\n",
        "**Operational Context**:\n",
        "\n",
        "- **Source Images (`src`)**: For original images, `metadata` is a singular dictionary encapsulating innate properties.\n",
        "\n",
        "- **Destination Images (`dest`)**: For processed or derivative images, `metadata` is presented as `metadataList`, each dictionary in the list detailing a distinct processing stage or configuration.\n",
        "\n",
        "\n",
        "In the context of visual programming, where data flow is typically represented in the form of nodes and connectors. Nodes essentially encapsulate functions, operations, or transformations. Inputs feed into these nodes, and after processing, the outputs emerge. This paradigm is particularly suitable for image processing workflows where an image undergoes a series of transformations.\n",
        "\n",
        "**Example 1: Output of a Node in Visual Programming (Source Image)**\n",
        "```\n",
        "output_node_torchvision_read_image = {\n",
        "    'dataType': 'torch.tensor',\n",
        "    'value': torch.tensor([3, 20, 20], device='cpu'),\n",
        "    'metadata': {\n",
        "        'colorSpace': 'rgb',\n",
        "        'channelOrder': 'first',\n",
        "        'isBatched': False,\n",
        "        'intensityRange': '0-255',  # Assuming default 8-bit image, modify if different\n",
        "        'device': 'cpu'  # Default device unless specified otherwise\n",
        "    }\n",
        "}\n",
        "```\n",
        "In this representation, the torchvision.io.read_image node has read an image file, and the output is a tensor with the RGB color space. The channels (RGB) come before the height and width dimensions (first), indicating the tensor's shape would be something like (3, height, width). The image isn't batched, and it's assumed to be on the CPU by default.\n",
        "\n",
        "**Example 2: Input for the matplotlib.imshow Node in Visual Programming**\n",
        "Given the specifications, the matplotlib.imshow node is flexible in accepting both RGB and grayscale images. Therefore, we'll create two metadata entries to cover both possibilities.\n",
        "```\n",
        "input_node_matplotlib_imshow = {\n",
        "    'dataType': 'numpy.ndarray',\n",
        "    'value': None,\n",
        "    'metadata': [\n",
        "        {\n",
        "            'colorSpace': 'rgb',\n",
        "            'channelOrder': 'last',\n",
        "            'isBatched': False,\n",
        "            'intensityRange': '0-255',\n",
        "            'device': 'cpu'\n",
        "        },\n",
        "        {\n",
        "            'colorSpace': 'grayscale',\n",
        "            'channelOrder': 'none',  # No channels for grayscale\n",
        "            'isBatched': False,\n",
        "            'intensityRange': '0-255',\n",
        "            'device': 'cpu'\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "```\n",
        "In this representation, the `matplotlib.imshow` node anticipates an input image that is either RGB (with shape H x W x C) or grayscale (with shape H x W). Both images are based on the numpy array format and are expected to be non-batched, 8-bit images processed on the CPU.\n",
        "\n",
        "This input representation can be used to validate or preprocess data before feeding it to the `matplotlib.imshow` node in the visual programming environment, ensuring compatibility and accurate visualization.\n",
        "\n",
        "The `Image` structure you've described is a well-defined and versatile representation for image data in modern computational environments, particularly with the ongoing fusion of scientific computing, data analysis, and machine learning. Here's a succinct summary and analysis of the `Image` structure:\n",
        "\n",
        "\n",
        "**Key Features**:\n",
        "1. **Flexibility**: `Image` can accommodate different data formats such as numpy arrays and tensors, catering to varied computational requirements.\n",
        "2. **Detailed Metadata**: The structure captures a wide range of metadata, from color space to computational platform, ensuring that the image data is interpretable and contextual.\n",
        "3. **Operational Context**: Distinct metadata formats for source and destination images allow for clearer lineage and transformation tracking.\n",
        "\n",
        "**Benefits**:\n",
        "- **Interoperability**: With the `dataType` attribute, it becomes easier to work between scientific computing and machine learning environments.\n",
        "- **Rich Context**: Comprehensive metadata provides critical details, making the image data self-descriptive. This is invaluable in pipelines where image provenance, transformation history, and computational context are crucial.\n",
        "- **Streamlined Processing**: The inclusion of details like `device`, `isBatched`, and `channelOrder` simplifies and optimizes image processing tasks, especially in machine learning workflows.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rGQeDgQK2UoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **State Machine Paradigm**:\n",
        "Absolutely, let's dive into a more scholarly, detailed examination of the `Image` data structure and its associated state machine for image data representation and transition. Deriving inspiration from formal computational theory, the associated state machine is architected to facilitate the seamless transition between various `dataTypes`. Each state in this machine corresponds to a distinct `dataType`, and the connectors or transition rules between these states delineate the requisite transformation protocols.\n",
        "\n",
        "\n",
        "- **States (Datatypes)**: Each viable `dataType` functions as a unique state within the machine. Examples include states for \"numpy.ndarray\", \"torch.tensor\", and potentially others as the ecosystem evolves.\n",
        "\n",
        "- **Transition Rules**: Dictate the conversion pathway between two states. For example, the rule might define how to transition an image from a \"numpy.ndarray\" to a \"torch.tensor\".\n",
        "\n",
        "- **Automated Conversion**: When leveraging a specific function or operation, users no longer need to delve into the intricacies of data conversion. The state machine, with its rules, identifies the necessary transitions and executes them, ensuring the data is always in the correct state.\n",
        "\n",
        "**Operational Benefits**:\n",
        "\n",
        "- **Efficiency**: Automated transitio By abstracting the transition logic and automating it, this mechanism reduces cognitive overhead for researchers and practitioners, allowing them to focus on higher-order image processing tasks.ns eliminate the need for redundant manual conversions, saving time and computational resources.\n",
        "\n",
        "- **Scalability**: The structure and associated state machine can easily accommodate new data types or transition rules as they emerge in the fast-evolving image processing landscape.\n",
        "\n",
        "- **Error Minimization**: By abstracting the conversion logic and embedding it within the state machine, the chances of errors, inconsistencies, or oversights are substantially reduced.\n"
      ],
      "metadata": {
        "id": "ro39aqUpN3EQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transition Rules in State Machine"
      ],
      "metadata": {
        "id": "VwAeEOLj3MQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### numpy.ndarray"
      ],
      "metadata": {
        "id": "3zcuSCPfivTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### numpy.ndarray to numpy.ndarray"
      ],
      "metadata": {
        "id": "wt58Uw0dH64U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ndarray2ndarray(src_image, dest_metadata_list):\n",
        "    import numpy as np\n",
        "    def find_matched_colorspace(src_metadata, dest_metadata_list):\n",
        "        # First, try matching the dataType\n",
        "        for metadata in dest_metadata_list:\n",
        "            if metadata[\"colorSpace\"] == src_metadata[\"colorSpace\"]:\n",
        "                return metadata\n",
        "\n",
        "        # Check for 'grb' or 'gbr' in src and match with 'rgb' or 'gbr' in dest\n",
        "        if src_metadata[\"colorSpace\"] in [\"grb\", \"gbr\"]:\n",
        "            for metadata in dest_metadata_list:\n",
        "                if metadata[\"colorSpace\"] in [\"rgb\", \"gbr\"]:\n",
        "                    return metadata\n",
        "\n",
        "        # If no match found, return the first metadata\n",
        "        return dest_metadata_list[0]\n",
        "\n",
        "    src_metadata = src_image[\"metadata\"]\n",
        "    dest_metadata = find_matched_colorspace(src_metadata, dest_metadata_list)\n",
        "    image = np.copy(src_image[\"value\"])\n",
        "    if src_metadata.get(\"isBatched\", False):\n",
        "        batch_dim = 0\n",
        "    else:\n",
        "        batch_dim = None\n",
        "\n",
        "    if (\n",
        "        src_metadata[\"colorSpace\"] == \"grayscale\"\n",
        "        and dest_metadata[\"colorSpace\"] == \"grayscale\"\n",
        "    ):\n",
        "        pass\n",
        "    elif (\n",
        "        src_metadata[\"colorSpace\"] == \"grayscale\"\n",
        "        and dest_metadata[\"colorSpace\"] != \"grayscale\"\n",
        "    ):\n",
        "        if batch_dim is not None:\n",
        "            image = np.repeat(image[..., np.newaxis], 3, axis=-1)\n",
        "        else:\n",
        "            image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\n",
        "    elif (\n",
        "        src_metadata[\"colorSpace\"] != \"grayscale\"\n",
        "        and dest_metadata[\"colorSpace\"] == \"grayscale\"\n",
        "    ):\n",
        "        if src_metadata[\"channelOrder\"] == \"first\":\n",
        "            if batch_dim is None:\n",
        "                if src_metadata[\"colorSpace\"] == \"rgb\":\n",
        "                    weights = np.array([0.299, 0.587, 0.114]).reshape(3, 1, 1)\n",
        "                else:  # gbr\n",
        "                    weights = np.array([0.587, 0.114, 0.299]).reshape(3, 1, 1)\n",
        "                image = np.sum(image * weights, axis=0)\n",
        "            else:\n",
        "                if src_metadata[\"colorSpace\"] == \"rgb\":\n",
        "                    weights = np.array([0.299, 0.587, 0.114]).reshape(1, 3, 1, 1)\n",
        "                else:\n",
        "                    weights = np.array([0.587, 0.114, 0.299]).reshape(1, 3, 1, 1)\n",
        "                image = np.sum(weights * weights, axis=1, keepdims=True)\n",
        "        else:\n",
        "            if batch_dim is not None:\n",
        "                if src_metadata[\"colorSpace\"] == \"rgb\":\n",
        "                    image = np.dot(image[..., :3], [0.299, 0.587, 0.114])\n",
        "                else:  # gbr\n",
        "                    image = np.dot(image[..., :3], [0.587, 0.114, 0.299])\n",
        "            else:\n",
        "                if src_metadata[\"colorSpace\"] == \"rgb\":\n",
        "                    image = np.dot(image[:, :3], [0.299, 0.587, 0.114])\n",
        "                else:\n",
        "                    image = np.dot(image[:, :3], [0.587, 0.114, 0.299])\n",
        "\n",
        "    elif src_metadata[\"colorSpace\"] == \"gbr\" and dest_metadata[\"colorSpace\"] == \"rgb\":\n",
        "        if src_metadata[\"channelOrder\"] == \"last\":\n",
        "            if batch_dim is not None:\n",
        "                image = image[..., [2, 0, 1]]\n",
        "            else:\n",
        "                image = image[:, :, [2, 0, 1]]\n",
        "        elif src_metadata[\"channelOrder\"] == \"first\":\n",
        "            if batch_dim is not None:\n",
        "                image = image[:, [2, 0, 1], :, :]\n",
        "            else:\n",
        "                image = image[[2, 0, 1], :, :]\n",
        "\n",
        "    elif src_metadata[\"colorSpace\"] == \"rgb\" and dest_metadata[\"colorSpace\"] == \"gbr\":\n",
        "        if src_metadata[\"channelOrder\"] == \"last\":\n",
        "            if batch_dim is not None:\n",
        "                image = image[..., [1, 2, 0]]\n",
        "            else:\n",
        "                image = image[:, :, [1, 2, 0]]\n",
        "        elif src_metadata[\"channelOrder\"] == \"first\":\n",
        "            if batch_dim is not None:\n",
        "                image = image[:, [1, 2, 0], :, :]\n",
        "            else:\n",
        "                image = image[[1, 2, 0], :, :]\n",
        "\n",
        "                # Adjust channel order\n",
        "    if (\n",
        "        src_metadata[\"channelOrder\"] == \"first\"\n",
        "        and dest_metadata[\"channelOrder\"] == \"last\"\n",
        "    ):\n",
        "        if batch_dim is not None:\n",
        "            image = np.transpose(image, (batch_dim, 2, 3, 1))\n",
        "        else:\n",
        "            image = np.transpose(\n",
        "                image, (1, 2, 0)\n",
        "            )  # Transpose to (height, width, channels)\n",
        "\n",
        "    if (\n",
        "        src_metadata[\"channelOrder\"] == \"last\"\n",
        "        and dest_metadata[\"channelOrder\"] == \"first\"\n",
        "    ):\n",
        "        if batch_dim is not None:\n",
        "            image = np.transpose(image, (batch_dim, 3, 1, 2))\n",
        "        else:\n",
        "            image = np.transpose(image, (2, 0, 1))\n",
        "\n",
        "    # Adjust intensity range\n",
        "    if (\n",
        "        src_metadata[\"intensityRange\"] == \"0-255\"\n",
        "        and dest_metadata[\"intensityRange\"] == \"0-1\"\n",
        "    ):\n",
        "        image = image / 255.0\n",
        "    elif (\n",
        "        src_metadata[\"intensityRange\"] == \"0-1\"\n",
        "        and dest_metadata[\"intensityRange\"] == \"0-255\"\n",
        "    ):\n",
        "        image = (image * 255).astype(np.uint8)\n",
        "\n",
        "    # Handle batched destination image with non-batched source image\n",
        "    if dest_metadata.get(\"isBatched\", False) and not src_metadata.get(\n",
        "        \"isBatched\", False\n",
        "    ):\n",
        "        image = np.expand_dims(image, 0)\n",
        "    elif not dest_metadata[\"isBatched\"] and src_metadata.get(\"isBatched\", False):\n",
        "        image = np.squeeze(image)\n",
        "\n",
        "    if dest_metadata[\"channelOrder\"] == \"none\":\n",
        "        if src_metadata[\"channelOrder\"] == \"first\":\n",
        "            image = image.squeeze()\n",
        "\n",
        "    # Create destination image with new metadata and converted values\n",
        "    dest_image = {\n",
        "        \"dataType\": src_image[\"dataType\"],\n",
        "        \"value\": image,\n",
        "        \"metadata\": dest_metadata,\n",
        "    }\n",
        "\n",
        "    return dest_image"
      ],
      "metadata": {
        "id": "GBarqqEBir2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_rgb_to_gbr():\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8),\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"gbr\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    converted_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    expected_shape = (100, 100, 3)\n",
        "    assert (\n",
        "        converted_image[\"value\"].shape == expected_shape\n",
        "    ), f\"Expected {expected_shape}, but got {converted_image['value'].shape}\"\n",
        "    assert (\n",
        "        converted_image[\"metadata\"][\"colorSpace\"] == \"gbr\"\n",
        "    ), f\"Expected color space 'gbr', but got {converted_image['metadata']['colorSpace']}\"\n",
        "\n",
        "    print(\"test_rgb_to_gbr PASSED\")\n",
        "\n",
        "\n",
        "def test_rgb_to_gbr_batched():\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.randint(0, 256, (5, 100, 100, 3), dtype=np.uint8),\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"dataType\": \"numpy.ndarray\",\n",
        "            \"colorSpace\": \"gbr\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    converted_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    expected_shape = (5, 100, 100, 3)\n",
        "    assert (\n",
        "        converted_image[\"value\"].shape == expected_shape\n",
        "    ), f\"Expected {expected_shape}, but got {converted_image['value'].shape}\"\n",
        "    assert (\n",
        "        converted_image[\"metadata\"][\"colorSpace\"] == \"gbr\"\n",
        "    ), f\"Expected color space 'gbr', but got {converted_image['metadata']['colorSpace']}\"\n",
        "\n",
        "    print(\"test_rgb_to_gbr_batched PASSED\")\n",
        "\n",
        "\n",
        "def test_intensity_conversion_0_1_to_0_255():\n",
        "    # Define source image metadata\n",
        "    src_metadata = {\n",
        "        \"colorSpace\": \"rgb\",\n",
        "        \"channelOrder\": \"last\",\n",
        "        \"isBatched\": False,\n",
        "        \"intensityRange\": \"0-1\",\n",
        "        \"device\": \"cpu\",\n",
        "    }\n",
        "\n",
        "    # Create a random source image\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.rand(100, 100, 3),\n",
        "        \"metadata\": src_metadata,\n",
        "    }\n",
        "\n",
        "    # Define destination metadata for intensity conversion\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert the image\n",
        "    converted_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "    expected_image = (src_image[\"value\"] * 255).astype(np.uint8)\n",
        "    assert np.allclose(\n",
        "        converted_image[\"value\"], expected_image\n",
        "    ), \"Intensity conversion not working\"\n",
        "\n",
        "    print(\"test_intensity_conversion_0_1_to_0_255 PASSED\")\n",
        "\n",
        "\n",
        "def test_channel_order_conversion():\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8),\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    converted_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    assert converted_image[\"value\"].shape == (\n",
        "        3,\n",
        "        100,\n",
        "        100,\n",
        "    ), f\"Expected (3, 100, 100), but got {converted_image['value'].shape}\"\n",
        "    assert (\n",
        "        converted_image[\"metadata\"][\"channelOrder\"] == \"first\"\n",
        "    ), f\"Expected channel order 'first', but got {converted_image['metadata']['channelOrder']}\"\n",
        "\n",
        "    print(\"test_channel_order_conversion PASSED\")\n",
        "\n",
        "\n",
        "def test_reverse_channel_order_conversion():\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.randint(0, 256, (3, 100, 100), dtype=np.uint8),\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",  # Source channel order is 'first'\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",  # Destination channel order is 'last'\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    converted_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    assert converted_image[\"value\"].shape == (\n",
        "        100,\n",
        "        100,\n",
        "        3,\n",
        "    ), f\"Expected (100, 100, 3), but got {converted_image['value'].shape}\"\n",
        "    print(\"test_reverse_channel_order_conversion PASSED\")\n",
        "\n",
        "\n",
        "def test_grayscale_to_rgb():\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.randint(0, 256, (100, 100), dtype=np.uint8),\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    converted_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    assert converted_image[\"value\"].shape == (100, 100, 3), \"Grayscale to RGB failed.\"\n",
        "    print(\"Grayscale to RGB passed.\")\n",
        "\n",
        "\n",
        "def test_channel_order_and_isBatched():\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8),\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    converted_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    assert converted_image[\"value\"].shape == (\n",
        "        1,\n",
        "        3,\n",
        "        100,\n",
        "        100,\n",
        "    ), f\"Expected (1, 3, 100, 100), but got {converted_image['value'].shape}\"\n",
        "    assert (\n",
        "        converted_image[\"metadata\"][\"channelOrder\"] == \"first\"\n",
        "    ), f\"Expected channel order 'first', but got {converted_image['metadata']['channelOrder']}\"\n",
        "    assert converted_image[\"metadata\"][\"isBatched\"], \"Expected isBatched to be True\"\n",
        "\n",
        "    print(\"test_channel_order_and_isBatched PASSED\")\n",
        "\n",
        "\n",
        "def test_non_batched_rgb_to_batched_rgb():\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.randint(\n",
        "            0, 256, (100, 100, 3), dtype=np.uint8\n",
        "        ),  # Non-batched RGB image\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,  # Source image is not batched\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": True,  # Destination image is batched\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    converted_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    assert converted_image[\"value\"].shape == (\n",
        "        1,\n",
        "        100,\n",
        "        100,\n",
        "        3,\n",
        "    ), f\"Expected (1, 100, 100, 3), but got {converted_image['value'].shape}\"\n",
        "    print(\"test_non_batched_rgb_to_batched_rgb PASSED\")\n",
        "\n",
        "\n",
        "def test_batched_grayscale_first_to_non_batched_no_channel_order():\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.randint(0, 256, (1, 1, 100, 100), dtype=np.uint8),\n",
        "        # Batched grayscale image with channel order 'first'\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": True,  # Source image is batched\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",  # No specified channel order for destination image\n",
        "            \"isBatched\": False,  # Destination image is not batched\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    converted_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    assert converted_image[\"value\"].shape == (\n",
        "        100,\n",
        "        100,\n",
        "    ), f\"Expected (100, 100), but got {converted_image['value'].shape}\"\n",
        "    print(\"test_batched_grayscale_first_to_non_batched_no_channel_order PASSED\")\n",
        "\n",
        "\n",
        "def test_grayscale_to_rgb_and_grayscale():\n",
        "    # 1*1*H*W\n",
        "    src_metadata = {\n",
        "        \"colorSpace\": \"grayscale\",\n",
        "        \"channelOrder\": \"first\",\n",
        "        \"isBatched\": True,\n",
        "        \"intensityRange\": \"0-1\",\n",
        "    }\n",
        "\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-1\",\n",
        "        },\n",
        "        {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-1\",\n",
        "        },\n",
        "    ]\n",
        "    src_image_value = np.random.random((1, 1, 256, 256))\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": src_image_value,\n",
        "        \"metadata\": src_metadata,\n",
        "    }\n",
        "\n",
        "    dest_image_grayscale = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    assert dest_image_grayscale[\"metadata\"][\"colorSpace\"] == \"grayscale\"\n",
        "    assert dest_image_grayscale[\"metadata\"][\"channelOrder\"] == \"none\"\n",
        "    assert not dest_image_grayscale[\"metadata\"][\"isBatched\"]\n",
        "    assert np.allclose(dest_image_grayscale[\"value\"], src_image_value[0][0])\n",
        "    print(\"test_batched_grayscale_first_to_more_then_one_metadatas PASSED\")\n",
        "\n",
        "\n",
        "def test_rgb_not_batched_channelfirst_gbr_batched_channellast():\n",
        "    C, H, W = 3, 64, 64\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": np.random.randint(0, 256, (C, H, W), dtype=np.uint8),\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"isBatched\": False,\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"intensityRange\": \"0-255\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"gbr\",\n",
        "            \"isBatched\": True,\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"intensityRange\": \"0-255\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    dest_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "    assert dest_image[\"value\"].shape == (1, H, W, C)\n",
        "\n",
        "    # Check values by converting both to RGB format and ensuring they match\n",
        "    expected_image = dest_image[\"value\"][0]  # batch size 1\n",
        "    expected_image = expected_image[..., [2, 0, 1]]  # Convert GBR to RGB\n",
        "    expected_image = np.transpose(expected_image, (2, 0, 1))\n",
        "    assert np.allclose(src_image[\"value\"], expected_image)\n",
        "    print(\"test_rgb_not_batched_channelfirst_gbr_batched_channellast PASSED\")\n",
        "\n",
        "\n",
        "def test_batched_channellast_rgb_to_not_batched_grayscale():\n",
        "    \"\"\"Test the conversion from RGB to grayscale for a non-batched image.\"\"\"\n",
        "\n",
        "    # Random RGB image with shape (1, height, width, channels)\n",
        "    H, W = 10, 10\n",
        "    src_value = np.random.randn(1, H, W, 3)\n",
        "\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": src_value,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert the image\n",
        "    dest_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    weights = np.array([0.299, 0.587, 0.114])\n",
        "    expected_value = (src_value * weights).sum(axis=-1)[0]  # Taking the first batch\n",
        "\n",
        "    # Check if the converted numpy array matches the expected numpy array\n",
        "    assert dest_image[\"value\"].shape == (H, W)\n",
        "    assert np.allclose(\n",
        "        dest_image[\"value\"], expected_value\n",
        "    ), \"Batched RGB to grayscale conversion failed.\"\n",
        "\n",
        "    print(\"test_batched_channellast_rgb_to_not_batched_grayscale PASSED\")\n",
        "\n",
        "\n",
        "def test_batched_channelfirst_rgb_to_not_batched_grayscale():\n",
        "    \"\"\"Test the conversion from batched RGB (channel first) to non-batched grayscale for numpy arrays.\"\"\"\n",
        "\n",
        "    # Random batched RGB image with dimensions (batchsize, channels, height, width)\n",
        "    H, W = 10, 10\n",
        "    src_value = np.random.randn(5, 3, H, W)\n",
        "\n",
        "    # Define source image and its metadata\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": src_value,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert the image\n",
        "    dest_image = ndarray2ndarray(src_image, dest_metadata_list)\n",
        "\n",
        "    # Expected grayscale image computed using the formula\n",
        "    weights = np.array([0.299, 0.587, 0.114])[:, None, None]\n",
        "    expected_value = (src_value[0] * weights).sum(axis=0)  # Using the first batch\n",
        "\n",
        "    # Check if the converted numpy array matches the expected numpy array\n",
        "    assert dest_image[\"value\"].shape == (H, W)\n",
        "    assert np.allclose(\n",
        "        dest_image[\"value\"], expected_value\n",
        "    ), \"Batched (channel first) RGB to grayscale conversion failed.\"\n",
        "\n",
        "    print(\"test_batched_channelfirst_rgb_to_not_batched_grayscale PASSED\")\n",
        "\n",
        "\n",
        "test_rgb_to_gbr()\n",
        "test_rgb_to_gbr_batched()\n",
        "test_grayscale_to_rgb()\n",
        "test_intensity_conversion_0_1_to_0_255()\n",
        "test_channel_order_conversion()\n",
        "test_channel_order_and_isBatched()\n",
        "test_reverse_channel_order_conversion()\n",
        "test_non_batched_rgb_to_batched_rgb()\n",
        "test_batched_grayscale_first_to_non_batched_no_channel_order()\n",
        "test_grayscale_to_rgb_and_grayscale()\n",
        "test_rgb_not_batched_channelfirst_gbr_batched_channellast()\n",
        "test_batched_channellast_rgb_to_not_batched_grayscale()\n",
        "test_batched_channellast_rgb_to_not_batched_grayscale()"
      ],
      "metadata": {
        "id": "5TlYmy3ETwBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b7b837-0306-4cf3-882e-302952682dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_rgb_to_gbr PASSED\n",
            "test_rgb_to_gbr_batched PASSED\n",
            "Grayscale to RGB passed.\n",
            "test_intensity_conversion_0_1_to_0_255 PASSED\n",
            "test_channel_order_conversion PASSED\n",
            "test_channel_order_and_isBatched PASSED\n",
            "test_reverse_channel_order_conversion PASSED\n",
            "test_non_batched_rgb_to_batched_rgb PASSED\n",
            "test_batched_grayscale_first_to_non_batched_no_channel_order PASSED\n",
            "test_batched_grayscale_first_to_more_then_one_metadatas PASSED\n",
            "test_rgb_not_batched_channelfirst_gbr_batched_channellast PASSED\n",
            "test_batched_channellast_rgb_to_not_batched_grayscale PASSED\n",
            "test_batched_channellast_rgb_to_not_batched_grayscale PASSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### numpy.ndarray to torch.tensor"
      ],
      "metadata": {
        "id": "gR8GxV1BIDOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ndarray2tensor(src_image):\n",
        "  import torch\n",
        "  torch_image = torch.tensor(src_image['value']).clone()\n",
        "  return {\n",
        "       'dataType': 'torch.tensor',\n",
        "        'value': torch_image,\n",
        "        'metadata': src_image['metadata']\n",
        "  }"
      ],
      "metadata": {
        "id": "FzcS6wziIIN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def test_ndarray_to_tensor():\n",
        "    src_metadata = {\n",
        "        \"colorSpace\": \"rgb\",\n",
        "        \"channelOrder\": \"first\",\n",
        "        \"isBatched\": False,\n",
        "        \"intensityRange\": \"0-255\",\n",
        "    }\n",
        "\n",
        "    src_image_value = np.random.random((3, 256, 256))\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": src_image_value,\n",
        "        \"metadata\": src_metadata,\n",
        "    }\n",
        "\n",
        "    dest_image = ndarray2tensor(src_image)\n",
        "\n",
        "    assert dest_image[\"metadata\"] == src_metadata\n",
        "    assert dest_image[\"dataType\"] == 'torch.tensor'\n",
        "    assert torch.equal(dest_image['value'], torch.tensor(src_image_value))\n",
        "    print(\"test_numpy_to_tensor PASSED\")\n",
        "\n",
        "test_ndarray_to_tensor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri_iiTAzQoio",
        "outputId": "26d4b1cb-ac8a-4e76-a3ac-80e46bef95f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_numpy_to_tensor PASSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.tensor"
      ],
      "metadata": {
        "id": "eARiqPgMhun4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### torch.tensor to torch.tensor"
      ],
      "metadata": {
        "id": "pEGNOSUsj5HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor2tensor(src_image, dest_metadata_list):\n",
        "    import torch\n",
        "\n",
        "    def find_matched_colorspace(src_metadata, dest_metadata_list):\n",
        "        # Same as the previous function, as this logic is independent of the data format\n",
        "        for metadata in dest_metadata_list:\n",
        "            if metadata[\"colorSpace\"] == src_metadata[\"colorSpace\"]:\n",
        "                return metadata\n",
        "\n",
        "        if src_metadata[\"colorSpace\"] in [\"grb\", \"gbr\"]:\n",
        "            for metadata in dest_metadata_list:\n",
        "                if metadata[\"colorSpace\"] in [\"rgb\", \"gbr\"]:\n",
        "                    return metadata\n",
        "\n",
        "        return dest_metadata_list[0]\n",
        "\n",
        "    src_metadata = src_image[\"metadata\"]\n",
        "    dest_metadata = find_matched_colorspace(src_metadata, dest_metadata_list)\n",
        "\n",
        "    # Make a copy of the source image\n",
        "    image = src_image[\"value\"].clone()\n",
        "\n",
        "    # Handle batched images\n",
        "    if src_metadata.get(\"isBatched\", False):\n",
        "        batch_dim = 0\n",
        "    else:\n",
        "        batch_dim = None\n",
        "\n",
        "    # Convert color space\n",
        "    if (\n",
        "        src_metadata[\"colorSpace\"] == \"grayscale\"\n",
        "        and dest_metadata[\"colorSpace\"] == \"grayscale\"\n",
        "    ):\n",
        "        pass  # No need for conversion\n",
        "    elif (\n",
        "        src_metadata[\"colorSpace\"] == \"grayscale\"\n",
        "        and dest_metadata[\"colorSpace\"] != \"grayscale\"\n",
        "    ):\n",
        "        image = image.unsqueeze(-1).repeat(1, 1, 1, 3)\n",
        "    elif (\n",
        "        src_metadata[\"colorSpace\"] != \"grayscale\"\n",
        "        and dest_metadata[\"colorSpace\"] == \"grayscale\"\n",
        "    ):\n",
        "        if src_metadata[\"channelOrder\"] == \"first\":\n",
        "            if src_metadata[\"colorSpace\"] == \"rgb\":\n",
        "                weights = (\n",
        "                    torch.tensor([0.299, 0.587, 0.114])\n",
        "                    .unsqueeze(-1)\n",
        "                    .unsqueeze(-1)\n",
        "                    .to(image.device)\n",
        "                )\n",
        "            else:  # gbr\n",
        "                weights = (\n",
        "                    torch.tensor([0.587, 0.114, 0.299])\n",
        "                    .unsqueeze(-1)\n",
        "                    .unsqueeze(-1)\n",
        "                    .to(image.device)\n",
        "                )\n",
        "            if batch_dim is not None:\n",
        "                image = (image * weights).sum(dim=1)\n",
        "            else:\n",
        "                image = (image * weights).sum(dim=0)\n",
        "        else:\n",
        "            if src_metadata[\"colorSpace\"] == \"rgb\":\n",
        "                weights = torch.tensor([0.299, 0.587, 0.114]).to(image.device)\n",
        "            else:  # gbr\n",
        "                weights = torch.tensor([0.587, 0.114, 0.299]).to(image.device)\n",
        "            if batch_dim is not None:\n",
        "                image = (image * weights).sum(dim=3)\n",
        "            else:\n",
        "                image = (image * weights).sum(dim=2)\n",
        "\n",
        "    elif src_metadata[\"colorSpace\"] == \"gbr\" and dest_metadata[\"colorSpace\"] == \"rgb\":\n",
        "        if src_metadata[\"channelOrder\"] == \"last\":\n",
        "            if batch_dim is not None:\n",
        "                image = image[..., [2, 0, 1]]\n",
        "            else:\n",
        "                image = image[:, :, [2, 0, 1]]\n",
        "        elif src_metadata[\"channelOrder\"] == \"first\":\n",
        "            if batch_dim is not None:\n",
        "                image = image[:, [2, 0, 1], :, :]\n",
        "            else:\n",
        "                image = image[[2, 0, 1], :, :]\n",
        "\n",
        "    elif src_metadata[\"colorSpace\"] == \"rgb\" and dest_metadata[\"colorSpace\"] == \"gbr\":\n",
        "        if src_metadata[\"channelOrder\"] == \"last\":\n",
        "            if batch_dim is not None:\n",
        "                image = image[..., [1, 2, 0]]\n",
        "            else:\n",
        "                image = image[:, :, [1, 2, 0]]\n",
        "        elif src_metadata[\"channelOrder\"] == \"first\":\n",
        "            if batch_dim is not None:\n",
        "                image = image[:, [1, 2, 0], :, :]\n",
        "            else:\n",
        "                image = image[[1, 2, 0], :, :]\n",
        "\n",
        "    # Adjust intensity range\n",
        "    if (\n",
        "        src_metadata[\"intensityRange\"] == \"0-255\"\n",
        "        and dest_metadata[\"intensityRange\"] == \"0-1\"\n",
        "    ):\n",
        "        image = image.float() / 255.0\n",
        "    elif (\n",
        "        src_metadata[\"intensityRange\"] == \"0-1\"\n",
        "        and dest_metadata[\"intensityRange\"] == \"0-255\"\n",
        "    ):\n",
        "        image = image * 255\n",
        "\n",
        "    # Adjust channel order\n",
        "    if (\n",
        "        src_metadata[\"channelOrder\"] == \"first\"\n",
        "        and dest_metadata[\"channelOrder\"] == \"last\"\n",
        "    ):\n",
        "        if batch_dim is not None:\n",
        "            image = image.permute(batch_dim, 2, 3, 1)\n",
        "        else:\n",
        "            image = image.permute(1, 2, 0)\n",
        "    elif (\n",
        "        src_metadata[\"channelOrder\"] == \"last\"\n",
        "        and dest_metadata[\"channelOrder\"] == \"first\"\n",
        "    ):\n",
        "        if batch_dim is not None:\n",
        "            image = image.permute(batch_dim, 3, 1, 2)\n",
        "        else:\n",
        "            image = image.permute(2, 0, 1)\n",
        "\n",
        "    # Handle batched destination image\n",
        "    if dest_metadata.get(\"isBatched\", False) and not src_metadata.get(\n",
        "        \"isBatched\", False\n",
        "    ):\n",
        "        image = image.unsqueeze(0)\n",
        "    elif not dest_metadata.get(\"isBatched\", False) and src_metadata.get(\n",
        "        \"isBatched\", False\n",
        "    ):\n",
        "        image = image.squeeze(0)\n",
        "\n",
        "    if dest_metadata[\"channelOrder\"] == \"none\":\n",
        "        if src_metadata[\"channelOrder\"] == \"first\":\n",
        "            image = image.squeeze(0)\n",
        "\n",
        "    # Create destination image with new metadata and converted values\n",
        "    dest_image = {\n",
        "        \"dataType\": src_image[\"dataType\"],\n",
        "        \"value\": image,\n",
        "        \"metadata\": dest_metadata,\n",
        "    }\n",
        "\n",
        "    return dest_image"
      ],
      "metadata": {
        "id": "IsuQ1TCRj4Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def assert_tensors_equal(tensor1, tensor2):\n",
        "    \"\"\"Utility function to check if two tensors are close in value.\"\"\"\n",
        "    assert torch.allclose(tensor1, tensor2), f\"Expected: {tensor1}, but got: {tensor2}\"\n",
        "\n",
        "\n",
        "def test_rgb_to_gbr():\n",
        "    \"\"\"Test the conversion from RGB to GBR for a non-batched image.\"\"\"\n",
        "    src_value = torch.randn(\n",
        "        10, 10, 3\n",
        "    )  # Random RGB image with shape (height, width, channels)\n",
        "\n",
        "    src_image = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"gbr\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    result = tensor2tensor(src_image, dest_metadata_list)\n",
        "\n",
        "    expected_value = src_value.clone()[:, :, [1, 2, 0]]  # Expected GBR image\n",
        "    assert_tensors_equal(result[\"value\"], expected_value)\n",
        "    print(\"test_rgb_to_gbr PASSED\")\n",
        "\n",
        "\n",
        "def test_rgb_to_gbr_batched():\n",
        "    # Adjust the intensityRange here to '0-1'\n",
        "    src_metadata = {\n",
        "        \"colorSpace\": \"rgb\",\n",
        "        \"channelOrder\": \"first\",\n",
        "        \"isBatched\": True,\n",
        "        \"intensityRange\": \"0-1\",\n",
        "    }\n",
        "\n",
        "    src_image_value = torch.randn((1, 3, 12, 12))\n",
        "    src_image = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_image_value,\n",
        "        \"metadata\": src_metadata,\n",
        "    }\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"gbr\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-1\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    dest_image = tensor2tensor(src_image, dest_metadata_list)\n",
        "    assert dest_image[\"value\"].shape == (3, 12, 12)\n",
        "    assert_tensors_equal(dest_image[\"value\"][0], src_image_value[0, 1])  # G channel\n",
        "    assert_tensors_equal(dest_image[\"value\"][1], src_image_value[0, 2])  # B channel\n",
        "    assert_tensors_equal(dest_image[\"value\"][2], src_image_value[0, 0])  # R channel\n",
        "\n",
        "    print(\"test_rgb_to_gbr_batched PASSED\")\n",
        "\n",
        "\n",
        "def test_channlelast_rgb_to_grayscale():\n",
        "    \"\"\"Test the conversion from RGB to grayscale for a non-batched image.\"\"\"\n",
        "\n",
        "    # Random RGB image with shape (height, width, channels)\n",
        "    src_value = torch.randn(10, 10, 3)\n",
        "\n",
        "    # Define source image and its metadata\n",
        "    src_image = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert the image\n",
        "    result = tensor2tensor(src_image, dest_metadata_list)\n",
        "\n",
        "    # Expected grayscale image computed using the formula\n",
        "    weights = torch.tensor([0.299, 0.587, 0.114]).to(src_value.device)\n",
        "    expected_value = (src_value * weights).sum(dim=-1)\n",
        "\n",
        "    # Check if the converted tensor matches the expected tensor\n",
        "    assert result[\"value\"].shape == (10, 10)\n",
        "    assert torch.allclose(\n",
        "        result[\"value\"], expected_value\n",
        "    ), \"RGB to grayscale conversion failed.\"\n",
        "\n",
        "    print(\"test_channlelast_rgb_to_grayscale PASSED\")\n",
        "\n",
        "\n",
        "def test_channlefirst_rgb_to_grayscale():\n",
        "    \"\"\"Test the conversion from RGB to grayscale for a non-batched image.\"\"\"\n",
        "\n",
        "    # Random RGB image with shape (height, width, channels)\n",
        "    src_value = torch.randn(3, 10, 10)\n",
        "\n",
        "    # Define source image and its metadata\n",
        "    src_image = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert the image\n",
        "    result = tensor2tensor(src_image, dest_metadata_list)\n",
        "\n",
        "    # Expected grayscale image\n",
        "    weights = (\n",
        "        torch.tensor([0.299, 0.587, 0.114])\n",
        "        .unsqueeze(-1)\n",
        "        .unsqueeze(-1)\n",
        "        .to(src_value.device)\n",
        "    )\n",
        "    expected_value = (src_value * weights).sum(dim=0)\n",
        "\n",
        "    # Check if the converted tensor matches the expected tensor\n",
        "    assert result[\"value\"].shape == (10, 10)\n",
        "    assert torch.allclose(\n",
        "        result[\"value\"], expected_value\n",
        "    ), \"Channel-first RGB to grayscale conversion failed.\"\n",
        "\n",
        "    print(\"test_channlefirst_rgb_to_grayscale PASSED\")\n",
        "\n",
        "\n",
        "def test_batched_channellast_rgb_to_not_batched_grayscale():\n",
        "    \"\"\"Test the conversion from RGB to grayscale for a non-batched image.\"\"\"\n",
        "\n",
        "    # Random RGB image with shape (1, height, width, channels)\n",
        "    src_value = torch.randn(1, 10, 10, 3)\n",
        "\n",
        "    # Define source image and its metadata\n",
        "    src_image = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert the image\n",
        "    result = tensor2tensor(src_image, dest_metadata_list)\n",
        "\n",
        "    # Expected grayscale image computed using the formula\n",
        "    weights = torch.tensor([0.299, 0.587, 0.114]).to(src_value.device)\n",
        "    expected_value = (src_value * weights).sum(dim=-1)\n",
        "\n",
        "    # Check if the converted tensor matches the expected tensor\n",
        "    assert result[\"value\"].shape == (10, 10)\n",
        "    assert torch.allclose(\n",
        "        result[\"value\"], expected_value\n",
        "    ), \"RGB to grayscale conversion failed.\"\n",
        "\n",
        "    print(\"test_batched_rgb_to_not_batched_grayscale PASSED\")\n",
        "\n",
        "\n",
        "def test_batched_channelfirst_rgb_to_not_batched_grayscale():\n",
        "    \"\"\"Test the conversion from RGB to grayscale for a non-batched image.\"\"\"\n",
        "\n",
        "    # Random RGB image with shape (1, height, width, channels)\n",
        "    src_value = torch.randn(1, 3, 10, 10)\n",
        "\n",
        "    # Define source image and its metadata\n",
        "    src_image = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert the image\n",
        "    result = tensor2tensor(src_image, dest_metadata_list)\n",
        "\n",
        "    # Expected grayscale image computed using the formula\n",
        "    weights = (\n",
        "        torch.tensor([0.299, 0.587, 0.114])\n",
        "        .unsqueeze(-1)\n",
        "        .unsqueeze(-1)\n",
        "        .to(src_value.device)\n",
        "    )\n",
        "    expected_value = (src_value * weights).sum(dim=1).squeeze(0)\n",
        "\n",
        "    # Check if the converted tensor matches the expected tensor\n",
        "    assert result[\"value\"].shape == (10, 10)\n",
        "    assert torch.allclose(\n",
        "        result[\"value\"], expected_value\n",
        "    ), \"RGB to grayscale conversion failed.\"\n",
        "\n",
        "    print(\"test_batched_rgb_to_not_batched_grayscale PASSED\")\n",
        "\n",
        "\n",
        "def test_intensity_conversion_0_1_to_0_255_rgb():\n",
        "    \"\"\"Test the intensity conversion from [0, 1] range to [0, 255] range for RGB images.\"\"\"\n",
        "\n",
        "    # Random RGB image with intensity values in [0, 1] range and shape (height, width, channels)\n",
        "    src_value = torch.rand(10, 10, 3)\n",
        "\n",
        "    # Define source image and its metadata\n",
        "    src_image = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-1\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert the image\n",
        "    result = tensor2tensor(src_image, dest_metadata_list)\n",
        "\n",
        "    # Expected RGB image with intensity values in [0, 255] range\n",
        "    expected_value = src_value * 255\n",
        "\n",
        "    # Check if the converted tensor matches the expected tensor\n",
        "    assert torch.all(\n",
        "        result[\"value\"] == expected_value\n",
        "    ), \"Intensity conversion from [0, 1] to [0, 255] for RGB images failed.\"\n",
        "\n",
        "    print(\"test_intensity_conversion_0_1_to_0_255_rgb PASSED\")\n",
        "\n",
        "\n",
        "def test_channel_order_conversion():\n",
        "    \"\"\"Test the channel order conversion between 'last' and 'first'.\"\"\"\n",
        "\n",
        "    # Random RGB image with shape (height, width, channels)\n",
        "    src_value_last_order = torch.randn(10, 10, 3)\n",
        "    src_value_first_order = src_value_last_order.permute(\n",
        "        2, 0, 1\n",
        "    )  # Convert to first order\n",
        "\n",
        "    # Define source images and their metadata\n",
        "    src_image_last = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value_last_order,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    src_image_first = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value_first_order,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list for conversions\n",
        "    dest_metadata_to_first = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    dest_metadata_to_last = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert images\n",
        "    result_to_first = tensor2tensor(src_image_last, dest_metadata_to_first)\n",
        "    result_to_last = tensor2tensor(src_image_first, dest_metadata_to_last)\n",
        "\n",
        "    # Check conversions\n",
        "    assert torch.all(\n",
        "        result_to_first[\"value\"] == src_value_first_order\n",
        "    ), \"Channel order conversion to 'first' failed.\"\n",
        "    assert torch.all(\n",
        "        result_to_last[\"value\"] == src_value_last_order\n",
        "    ), \"Channel order conversion to 'last' failed.\"\n",
        "\n",
        "    print(\"test_channel_order_conversion PASSED\")\n",
        "\n",
        "\n",
        "def test_batched_channel_order_conversion():\n",
        "    \"\"\"Test the channel order conversion with batched destination images.\"\"\"\n",
        "\n",
        "    # Random RGB image with shape (height, width, channels)\n",
        "    src_value_last_order = torch.randn(10, 10, 3)\n",
        "    src_value_first_order = src_value_last_order.permute(\n",
        "        2, 0, 1\n",
        "    )  # Convert to 'first' order\n",
        "\n",
        "    # Define source images and their metadata\n",
        "    src_image_last = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value_last_order,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    src_image_first = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value_first_order,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list for conversions\n",
        "    dest_metadata_batched_to_first = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    dest_metadata_batched_to_last = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert images\n",
        "    result_to_first = tensor2tensor(src_image_last, dest_metadata_batched_to_first)\n",
        "    result_to_last = tensor2tensor(src_image_first, dest_metadata_batched_to_last)\n",
        "\n",
        "    # Check conversions\n",
        "    assert torch.all(\n",
        "        result_to_first[\"value\"][0] == src_value_first_order\n",
        "    ), \"Conversion to batched 'first' order failed.\"\n",
        "    assert torch.all(\n",
        "        result_to_last[\"value\"][0] == src_value_last_order\n",
        "    ), \"Conversion to batched 'last' order failed.\"\n",
        "\n",
        "    print(\"test_batched_channel_order_conversion PASSED\")\n",
        "\n",
        "\n",
        "def assert_tensors_equal(tensor1, tensor2):\n",
        "    \"\"\"Utility function to assert if two tensors are equal.\"\"\"\n",
        "    assert torch.all(tensor1 == tensor2), \"Tensors are not equal.\"\n",
        "\n",
        "\n",
        "def test_batched_grayscale_first_to_non_batched_no_channel_order():\n",
        "    \"\"\"Test the conversion from a batched, channels-first grayscale image to a non-batched, no channel order grayscale image.\"\"\"\n",
        "\n",
        "    # Random grayscale batched image with shape (batch, channels, height, width)\n",
        "    src_value = torch.randn(1, 1, 10, 10)\n",
        "\n",
        "    # Source image metadata\n",
        "    src_metadata = {\n",
        "        \"colorSpace\": \"grayscale\",\n",
        "        \"channelOrder\": \"first\",\n",
        "        \"isBatched\": True,\n",
        "        \"intensityRange\": \"0-255\",\n",
        "        \"device\": \"cpu\",\n",
        "    }\n",
        "\n",
        "    # Destination metadata for a non-batched image with no channel order\n",
        "    dest_metadata_list = [\n",
        "        {\n",
        "            \"colorSpace\": \"grayscale\",\n",
        "            \"channelOrder\": \"none\",  # No channel order for the destination\n",
        "            \"isBatched\": False,  # Destination is non-batched\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Construct source image\n",
        "    src_image = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value,\n",
        "        \"metadata\": src_metadata,\n",
        "    }\n",
        "\n",
        "    # Convert using tensor2tensor\n",
        "    result = tensor2tensor(src_image, dest_metadata_list)\n",
        "\n",
        "    # Expected result: Remove the batch and channel dimensions\n",
        "    expected_value = src_value[0, 0]\n",
        "\n",
        "    # Check the conversion directly using the assert statement\n",
        "    assert torch.all(\n",
        "        result[\"value\"] == expected_value\n",
        "    ), \"The converted tensor does not match the expected tensor.\"\n",
        "\n",
        "    print(\"test_batched_grayscale_first_to_non_batched_no_channel_order PASSED\")\n",
        "\n",
        "\n",
        "def test_not_batched_gbr_to_batched_rgb_channelorder_conversion():\n",
        "    \"\"\"Test the GBR to RGB conversion with batched destination images.\"\"\"\n",
        "\n",
        "    # Random GBR image with shape (height, width, channels)\n",
        "    src_value_last_order = torch.randn(10, 10, 3)\n",
        "    src_value_first_order = src_value_last_order.permute(\n",
        "        2, 0, 1\n",
        "    )  # Convert to 'first' order\n",
        "\n",
        "    # Define source images and their metadata for GBR color space\n",
        "    src_image_last_gbr = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value_last_order,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"gbr\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    src_image_first_gbr = {\n",
        "        \"dataType\": \"torch.tensor\",\n",
        "        \"value\": src_value_first_order,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"gbr\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": False,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Destination metadata list for RGB conversions\n",
        "    dest_metadata_batched_to_first_rgb = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    dest_metadata_batched_to_last_rgb = [\n",
        "        {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"channelOrder\": \"last\",\n",
        "            \"isBatched\": True,\n",
        "            \"intensityRange\": \"0-255\",\n",
        "            \"device\": \"cpu\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert images\n",
        "    result_to_first_rgb = tensor2tensor(\n",
        "        src_image_last_gbr,\n",
        "        dest_metadata_batched_to_first_rgb,\n",
        "    )\n",
        "    result_to_last_rgb = tensor2tensor(\n",
        "        src_image_first_gbr,\n",
        "        dest_metadata_batched_to_last_rgb,\n",
        "    )\n",
        "\n",
        "    # Expected RGB values\n",
        "    expected_value_first_rgb = (\n",
        "        src_value_last_order[:, :, [2, 0, 1]].unsqueeze(0).permute(0, 3, 1, 2)\n",
        "    )  # Convert GBR to RGB and add batch dimension\n",
        "    expected_value_last_rgb = src_value_first_order.permute(1, 2, 0)[\n",
        "        :, :, [2, 0, 1]\n",
        "    ].unsqueeze(\n",
        "        0\n",
        "    )  # Convert GBR to RGB, add batch dimension\n",
        "\n",
        "    # Check conversions\n",
        "    assert torch.all(\n",
        "        result_to_first_rgb[\"value\"] == expected_value_first_rgb\n",
        "    ), \"Conversion to batched 'first' order failed.\"\n",
        "    assert torch.all(\n",
        "        result_to_last_rgb[\"value\"] == expected_value_last_rgb\n",
        "    ), \"Conversion to batched 'last' order failed.\"\n",
        "\n",
        "    print(\"test_not_batched_gbr_to_batched_rgb_channelorder_conversion PASSED\")\n",
        "\n",
        "\n",
        "test_rgb_to_gbr()\n",
        "test_rgb_to_gbr_batched()\n",
        "test_channlelast_rgb_to_grayscale()\n",
        "test_channlefirst_rgb_to_grayscale()\n",
        "test_batched_channellast_rgb_to_not_batched_grayscale()\n",
        "test_batched_channelfirst_rgb_to_not_batched_grayscale()\n",
        "test_intensity_conversion_0_1_to_0_255_rgb()\n",
        "test_channel_order_conversion()\n",
        "test_batched_channel_order_conversion()\n",
        "test_batched_grayscale_first_to_non_batched_no_channel_order()\n",
        "test_not_batched_gbr_to_batched_rgb_channelorder_conversion()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDYtLobPlWna",
        "outputId": "61e940ec-f055-4650-c7ba-fcc6797981d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_rgb_to_gbr PASSED\n",
            "test_rgb_to_gbr_batched PASSED\n",
            "test_channlelast_rgb_to_grayscale PASSED\n",
            "test_channlefirst_rgb_to_grayscale PASSED\n",
            "test_batched_rgb_to_not_batched_grayscale PASSED\n",
            "test_batched_rgb_to_not_batched_grayscale PASSED\n",
            "test_intensity_conversion_0_1_to_0_255_rgb PASSED\n",
            "test_channel_order_conversion PASSED\n",
            "test_batched_channel_order_conversion PASSED\n",
            "test_batched_grayscale_first_to_non_batched_no_channel_order PASSED\n",
            "test_not_batched_gbr_to_batched_rgb_channelorder_conversion PASSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### torch.tensor to numpy.ndarray"
      ],
      "metadata": {
        "id": "hky_JG1PhyBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor2ndarray(src_image):\n",
        "  import copy\n",
        "  numpy_image = copy.deepcopy(src_image['value'].cpu().numpy())\n",
        "  return {\n",
        "       'dataType': 'numpy.ndarray',\n",
        "       'value': numpy_image,\n",
        "       'metadata': src_image['metadata']\n",
        "  }"
      ],
      "metadata": {
        "id": "gOA25HeGiLTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy\n",
        "def test_tensor_to_ndarray():\n",
        "    src_metadata = {\n",
        "        \"colorSpace\": \"rgb\",\n",
        "        \"channelOrder\": \"first\",\n",
        "        \"isBatched\": False,\n",
        "        \"intensityRange\": \"0-255\",\n",
        "    }\n",
        "\n",
        "    src_image_value = torch.randn(3, 256, 256)\n",
        "    src_image = {\n",
        "        \"dataType\": \"\",\n",
        "        \"value\": src_image_value,\n",
        "        \"metadata\": src_metadata,\n",
        "    }\n",
        "\n",
        "    dest_image = tensor2ndarray(src_image)\n",
        "\n",
        "    assert dest_image[\"metadata\"] == src_metadata\n",
        "    assert dest_image[\"dataType\"] == 'numpy.ndarray'\n",
        "    assert numpy.array_equal(dest_image['value'], src_image_value.numpy())\n",
        "    print(\"test_tensor_to_numpy PASSED\")\n",
        "\n",
        "test_tensor_to_ndarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7cbWC92izpn",
        "outputId": "cdb232f2-88ed-4e2f-d0b7-2c82b477fb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_tensor_to_numpy PASSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit test of State Machine"
      ],
      "metadata": {
        "id": "aA-rwA8sOWaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unit test 1: **Image (torch.tensor, rgb, 0-255, (3, H, W)** to **Image (numpy.ndarray, gbr, 0-1, (1, H, W, 3))**\n"
      ],
      "metadata": {
        "id": "hhuerhY-hzQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def test_tensor_to_numpy_to_numpy():\n",
        "    # RGB image of shape (3, H, W) with values between 0-255\n",
        "    H, W = 64, 64\n",
        "    src_image_value = torch.randint(0, 256, (3, H, W), dtype=torch.float32)\n",
        "    src_image = {\n",
        "        'dataType': 'torch.tensor',\n",
        "        'value': src_image_value,\n",
        "        'metadata': {\n",
        "            'colorSpace': 'rgb',\n",
        "            'isBatched': False,\n",
        "            'channelOrder': 'first',\n",
        "            'intensityRange': '0-255'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # GBR image of shape (1, H, W, 3) with values between 0-1\n",
        "    dest_metadata_list = [{\n",
        "        'colorSpace': 'gbr',\n",
        "        'isBatched': True,\n",
        "        'channelOrder': 'last',\n",
        "        'intensityRange': '0-1'\n",
        "    }]\n",
        "\n",
        "    intermediate_numpy = tensor2ndarray(src_image)\n",
        "    assert intermediate_numpy['dataType'] == 'numpy.ndarray'\n",
        "    assert intermediate_numpy['metadata'] == src_image['metadata']\n",
        "    assert intermediate_numpy['value'].shape == (3, H, W)\n",
        "    assert np.allclose(intermediate_numpy['value'], src_image['value'].numpy())\n",
        "\n",
        "    dest_image = ndarray2ndarray(intermediate_numpy, dest_metadata_list)\n",
        "\n",
        "    assert dest_image['dataType'] == 'numpy.ndarray'\n",
        "    assert dest_image['metadata'] == dest_metadata_list[0]\n",
        "    assert dest_image['value'].shape == (1, H, W, 3)\n",
        "\n",
        "    converted_numpy = dest_image['value'][0] # Batch size\n",
        "    converted_numpy = converted_numpy[..., [2, 0, 1]]  # Convert GBR to RGB\n",
        "    converted_numpy = np.transpose(converted_numpy, (2, 0, 1)) # Channdel order\n",
        "    assert np.allclose(src_image_value / 255.0, converted_numpy)\n",
        "    print(\"test_from_tensor_to_numpy_to_numpy PASSED\")\n",
        "\n",
        "test_tensor_to_numpy_to_numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srCtXw5RSjUL",
        "outputId": "9765fedf-724b-4e3c-eb9a-f2568f7920f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_from_tensor_to_numpy_to_numpy PASSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unit test 2:  **Image (numpy.ndarray, rgb, 0-1, (1, 3, H, W))** to **Image (torch.tensor, grayscale, 0-255, (H, W))**"
      ],
      "metadata": {
        "id": "9d02RHZhMfvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def test_numpy_to_tensor_to_tensor():\n",
        "    # RGB image of shape (1, 3, H, W) with values between 0-1\n",
        "    H, W = 64, 64\n",
        "    src_image_value = np.random.rand(1, 3, H, W).astype(np.float32)\n",
        "    src_image = {\n",
        "        \"dataType\": \"numpy.ndarray\",\n",
        "        \"value\": src_image_value,\n",
        "        \"metadata\": {\n",
        "            \"colorSpace\": \"rgb\",\n",
        "            \"isBatched\": True,\n",
        "            \"channelOrder\": \"first\",\n",
        "            \"intensityRange\": \"0-1\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Grayscale image of shape (H, W) with values between 0-255\n",
        "    dest_metadata_list = [{\n",
        "        \"colorSpace\": \"grayscale\",\n",
        "        \"isBatched\": False,\n",
        "        \"channelOrder\": \"none\",\n",
        "        \"intensityRange\": \"0-255\"\n",
        "    }]\n",
        "\n",
        "    intermediate_image = ndarray2tensor(src_image)\n",
        "\n",
        "    assert intermediate_image[\"dataType\"] == \"torch.tensor\"\n",
        "    assert intermediate_image[\"metadata\"] == src_image['metadata']\n",
        "    assert intermediate_image[\"value\"].shape == (1, 3, H, W)\n",
        "    assert np.array_equal(src_image[\"value\"], intermediate_image[\"value\"].numpy()), \"Values in src_image and intermediate_image do not match!\"\n",
        "\n",
        "\n",
        "    dest_image = tensor2tensor(intermediate_image, dest_metadata_list)\n",
        "\n",
        "    assert dest_image[\"dataType\"] == \"torch.tensor\"\n",
        "    assert dest_image[\"metadata\"] == dest_metadata_list[0]\n",
        "    assert dest_image[\"value\"].shape == (H, W)\n",
        "    weight = torch.tensor([0.299, 0.587, 0.114]).unsqueeze(-1).unsqueeze(-1)\n",
        "    assert  torch.allclose(dest_image[\"value\"], (intermediate_image[\"value\"][0] * weight *255).sum(dim=0))\n",
        "\n",
        "    print(\"test_numpy_to_tensor_to_tensor PASSED\")\n",
        "\n",
        "test_numpy_to_tensor_to_tensor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4VCvql2aK0m",
        "outputId": "d428b069-4f4d-4f50-a812-c16c4f25ec83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_numpy_to_tensor_to_tensor PASSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State Machine Configuration in Visual Programming"
      ],
      "metadata": {
        "id": "XjQZ7BVQOGIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` json\n",
        "{\n",
        "    \"imageTypeConversion\": {\n",
        "        \"numpy.ndarray\": {\n",
        "            \"numpy.ndarray\": {\n",
        "                \"function_definition\": \"def ndarray2ndarray(src_image, dest_metadata_list):\\n    import numpy as np\\n    def find_matched_colorspace(src_metadata, dest_metadata_list):\\n        # First, try matching the dataType\\n        for metadata in dest_metadata_list:\\n            if metadata[\\\"colorSpace\\\"] == src_metadata[\\\"colorSpace\\\"]:\\n                return metadata\\n\\n        # Check for 'grb' or 'gbr' in src and match with 'rgb' or 'gbr' in dest\\n        if src_metadata[\\\"colorSpace\\\"] in [\\\"grb\\\", \\\"gbr\\\"]:\\n            for metadata in dest_metadata_list:\\n                if metadata[\\\"colorSpace\\\"] in [\\\"rgb\\\", \\\"gbr\\\"]:\\n                    return metadata\\n\\n        # If no match found, return the first metadata\\n        return dest_metadata_list[0]\\n\\n    src_metadata = src_image[\\\"metadata\\\"]\\n    dest_metadata = find_matched_colorspace(src_metadata, dest_metadata_list)\\n    image = np.copy(src_image[\\\"value\\\"])\\n    if src_metadata.get(\\\"isBatched\\\", False):\\n        batch_dim = 0\\n    else:\\n        batch_dim = None\\n\\n    if (\\n        src_metadata[\\\"colorSpace\\\"] == \\\"grayscale\\\"\\n        and dest_metadata[\\\"colorSpace\\\"] == \\\"grayscale\\\"\\n    ):\\n        pass\\n    elif (\\n        src_metadata[\\\"colorSpace\\\"] == \\\"grayscale\\\"\\n        and dest_metadata[\\\"colorSpace\\\"] != \\\"grayscale\\\"\\n    ):\\n        if batch_dim is not None:\\n            image = np.repeat(image[..., np.newaxis], 3, axis=-1)\\n        else:\\n            image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\\n    elif (\\n        src_metadata[\\\"colorSpace\\\"] != \\\"grayscale\\\"\\n        and dest_metadata[\\\"colorSpace\\\"] == \\\"grayscale\\\"\\n    ):\\n        if src_metadata[\\\"channelOrder\\\"] == \\\"first\\\":\\n            if batch_dim is None:\\n                if src_metadata[\\\"colorSpace\\\"] == \\\"rgb\\\":\\n                    weights = np.array([0.299, 0.587, 0.114]).reshape(3, 1, 1)\\n                else:  # gbr\\n                    weights = np.array([0.587, 0.114, 0.299]).reshape(3, 1, 1)\\n                image = np.sum(image * weights, axis=0)\\n            else:\\n                if src_metadata[\\\"colorSpace\\\"] == \\\"rgb\\\":\\n                    weights = np.array([0.299, 0.587, 0.114]).reshape(1, 3, 1, 1)\\n                else:\\n                    weights = np.array([0.587, 0.114, 0.299]).reshape(1, 3, 1, 1)\\n                image = np.sum(weights * weights, axis=1, keepdims=True)\\n        else:\\n            if batch_dim is not None:\\n                if src_metadata[\\\"colorSpace\\\"] == \\\"rgb\\\":\\n                    image = np.dot(image[..., :3], [0.299, 0.587, 0.114])\\n                else:  # gbr\\n                    image = np.dot(image[..., :3], [0.587, 0.114, 0.299])\\n            else:\\n                if src_metadata[\\\"colorSpace\\\"] == \\\"rgb\\\":\\n                    image = np.dot(image[:, :3], [0.299, 0.587, 0.114])\\n                else:\\n                    image = np.dot(image[:, :3], [0.587, 0.114, 0.299])\\n\\n    elif src_metadata[\\\"colorSpace\\\"] == \\\"gbr\\\" and dest_metadata[\\\"colorSpace\\\"] == \\\"rgb\\\":\\n        if src_metadata[\\\"channelOrder\\\"] == \\\"last\\\":\\n            if batch_dim is not None:\\n                image = image[..., [2, 0, 1]]\\n            else:\\n                image = image[:, :, [2, 0, 1]]\\n        elif src_metadata[\\\"channelOrder\\\"] == \\\"first\\\":\\n            if batch_dim is not None:\\n                image = image[:, [2, 0, 1], :, :]\\n            else:\\n                image = image[[2, 0, 1], :, :]\\n\\n    elif src_metadata[\\\"colorSpace\\\"] == \\\"rgb\\\" and dest_metadata[\\\"colorSpace\\\"] == \\\"gbr\\\":\\n        if src_metadata[\\\"channelOrder\\\"] == \\\"last\\\":\\n            if batch_dim is not None:\\n                image = image[..., [1, 2, 0]]\\n            else:\\n                image = image[:, :, [1, 2, 0]]\\n        elif src_metadata[\\\"channelOrder\\\"] == \\\"first\\\":\\n            if batch_dim is not None:\\n                image = image[:, [1, 2, 0], :, :]\\n            else:\\n                image = image[[1, 2, 0], :, :]\\n\\n                # Adjust channel order\\n    if (\\n        src_metadata[\\\"channelOrder\\\"] == \\\"first\\\"\\n        and dest_metadata[\\\"channelOrder\\\"] == \\\"last\\\"\\n    ):\\n        if batch_dim is not None:\\n            image = np.transpose(image, (batch_dim, 2, 3, 1))\\n        else:\\n            image = np.transpose(\\n                image, (1, 2, 0)\\n            )  # Transpose to (height, width, channels)\\n\\n    if (\\n        src_metadata[\\\"channelOrder\\\"] == \\\"last\\\"\\n        and dest_metadata[\\\"channelOrder\\\"] == \\\"first\\\"\\n    ):\\n        if batch_dim is not None:\\n            image = np.transpose(image, (batch_dim, 3, 1, 2))\\n        else:\\n            image = np.transpose(image, (2, 0, 1))\\n\\n    # Adjust intensity range\\n    if (\\n        src_metadata[\\\"intensityRange\\\"] == \\\"0-255\\\"\\n        and dest_metadata[\\\"intensityRange\\\"] == \\\"0-1\\\"\\n    ):\\n        image = image / 255.0\\n    elif (\\n        src_metadata[\\\"intensityRange\\\"] == \\\"0-1\\\"\\n        and dest_metadata[\\\"intensityRange\\\"] == \\\"0-255\\\"\\n    ):\\n        image = (image * 255).astype(np.uint8)\\n\\n    # Handle batched destination image with non-batched source image\\n    if dest_metadata.get(\\\"isBatched\\\", False) and not src_metadata.get(\\n        \\\"isBatched\\\", False\\n    ):\\n        image = np.expand_dims(image, 0)\\n    elif not dest_metadata[\\\"isBatched\\\"] and src_metadata.get(\\\"isBatched\\\", False):\\n        image = np.squeeze(image)\\n\\n    if dest_metadata[\\\"channelOrder\\\"] == \\\"none\\\":\\n        if src_metadata[\\\"channelOrder\\\"] == \\\"first\\\":\\n            image = image.squeeze()\\n\\n    # Create destination image with new metadata and converted values\\n    dest_image = {\\n        \\\"dataType\\\": src_image[\\\"dataType\\\"],\\n        \\\"value\\\": image,\\n        \\\"metadata\\\": dest_metadata,\\n    }\\n\\n    return dest_image\",\n",
        "                \"function_name\": \"ndarray2ndarray\"\n",
        "            },\n",
        "            \"torch.tensor\": {\n",
        "                \"function_definition\": \"def ndarray2tensor(src_image):\\n  import torch\\n  torch_image = torch.tensor(src_image['value']).clone()\\n  return {\\n       'dataType': 'torch.tensor',\\n        'value': torch_image,\\n        'metadata': src_image['metadata']\\n  }\\n  return dest;\",\n",
        "                \"function_name\": \"ndarray2tensor\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "fVC2r7SzSyP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```json\n",
        "    \"read_image\": {\n",
        "      \"type\": \"read_image\",\n",
        "      \"category\": \"function\",\n",
        "      \"title\": \"read_image\",\n",
        "      \"tooltip\": \"Reads a JPEG or PNG image into a 3 dimensional RGB or grayscale Tensor. Optionally converts the image to the desired format. The values of the output tensor are uint8 in [0, 255].\",\n",
        "      \"externalImports\": \"from torchvision import io\\nfrom torchvision.io import ImageReadMode\",\n",
        "      \"sourceCode\": \"{{indent}}{{{output1}}} = io.read_image({{{inputs.1}}}, {{{inputs.2}}})\\n{{{output1}}} = {'value': {{{output1}}}, 'dataType': 'torch.tensor', 'metadata': {'colorSpace': 'rgb', 'channelOrder': 'first', 'isBatched': False, 'intensityRange': '0-255', 'device': 'cpu'}}\\n{{{outputs.0}}}\",\n",
        "      \"inputs\": {\n",
        "        \"execIn\": {\n",
        "          \"title\": \"execIn\",\n",
        "          \"tooltip\": \"execIn\",\n",
        "          \"dataType\": \"exec\",\n",
        "          \"showWidget\": false,\n",
        "          \"showTitle\": false\n",
        "        },\n",
        "        \"path\": {\n",
        "          \"title\": \"path\",\n",
        "          \"dataType\": \"string\",\n",
        "          \"tooltip\": \"path(str) - path of the JPEG or PNG image.\"\n",
        "        },\n",
        "        \"mode\": {\n",
        "          \"title\": \"mode\",\n",
        "          \"dataType\": \"imageio.ImageReadMode\",\n",
        "          \"default\": \"ImageReadMode.UNCHANGED\",\n",
        "          \"tooltip\": \"mode(ImageReadMode) - The read mode used for optionally converting the image. Default: ImageReadMode.UNCHANGED.\"\n",
        "        }\n",
        "      },\n",
        "      \"outputs\": {\n",
        "        \"execOut\": {\n",
        "          \"title\": \"execOut\",\n",
        "          \"tooltip\": \"execOut\",\n",
        "          \"dataType\": \"exec\",\n",
        "          \"showWidget\": false,\n",
        "          \"showTitle\": false\n",
        "        },\n",
        "        \"image\": {\n",
        "          \"title\": \"image\",\n",
        "          \"dataType\": \"image\",\n",
        "          \"defaultValue\": {\n",
        "            \"dataType\": \"torch.tensor\"\n",
        "          },\n",
        "          \"tooltip\": \"{dataType: torch.tensor, value, layout: [chw], colorMode: [rgb, grayscale], intensityRange: 0-255' device: cpu}\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "```"
      ],
      "metadata": {
        "id": "tLOJ-SuOcGn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual vs Image Data Transition in Visual Programming Environment\n"
      ],
      "metadata": {
        "id": "XugdWHXX8CuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Seamless Image Data Transitions via a Configurable State Machine](Seamless Image Data Transitions via a Configurable State Machine.jpg)"
      ],
      "metadata": {
        "id": "rhQ4_Ohxph1u"
      }
    }
  ]
}